{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of cluster tree usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation (if needed)\n",
    "\n",
    "**Note**: replace cupy-cuda110 with your cuda version!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cupy-cuda110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall py-boost\n",
    "# !cd ..; bash build_package.sh\n",
    "# !pip install ../dist/Py_Boost-0.1.8-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Optional: set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# simple case - just one class is used\n",
    "from py_boost import GradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of dummy regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.06 s, sys: 1.29 s, total: 3.35 s\n",
      "Wall time: 826 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = make_regression(150000, 100, n_targets=1, random_state=42)\n",
    "X_test, y_test = X[:50000], y[:50000]\n",
    "X, y = X[-50000:], y[-50000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a GBDT model\n",
    "\n",
    "The only argument required here is a loss function. It, together with the input target shape, determines the task type. The loss function can be passed as a Loss instance or using a string alias:\n",
    "\n",
    "* ***'mse'*** for the regression/multitask regression\n",
    "* ***'msle'*** for the regression/multitask regression\n",
    "* ***'bce'*** for the binary/multilabel classification\n",
    "* ***'crossentropy'*** for the multiclassification\n",
    "\n",
    "Training is simply done by calling the .fit metod. Possible argumentsare the following:\n",
    "\n",
    "* ***'X'*** \n",
    "* ***'y'*** \n",
    "* ***'sample_weight'*** \n",
    "* ***'eval_sets'***  \n",
    "A validation set is passed as a list of dicts with possible keys ['X', 'y', 'sample_weight']. Note: if multiple valid sets are passed, the best model is selected using the last one.\n",
    "\n",
    "#### The example below illustrates how to train a simple regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:51:30] Stdout logging level is INFO.\n",
      "[19:51:30] GDBT train starts. Max iter 1000, early stopping rounds 100\n",
      "[19:51:30] Iter 0; Sample 0, rmse = 175.085401707104; \n",
      "[19:51:31] Iter 100; Sample 0, rmse = 34.704968699444635; \n",
      "[19:51:32] Iter 200; Sample 0, rmse = 18.87524749221564; \n",
      "[19:51:33] Iter 300; Sample 0, rmse = 15.978965345652862; \n",
      "[19:51:34] Iter 400; Sample 0, rmse = 15.373245716125354; \n",
      "[19:51:35] Iter 500; Sample 0, rmse = 15.218444378728087; \n",
      "[19:51:36] Iter 600; Sample 0, rmse = 15.164194374641644; \n",
      "[19:51:36] Iter 700; Sample 0, rmse = 15.094284385839273; \n",
      "[19:51:37] Iter 800; Sample 0, rmse = 15.029151646091728; \n",
      "[19:51:38] Iter 900; Sample 0, rmse = 14.96591336234754; \n",
      "[19:51:39] Iter 999; Sample 0, rmse = 14.916066868203313; \n",
      "CPU times: user 11.8 s, sys: 818 ms, total: 12.6 s\n",
      "Wall time: 11.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f829813cd90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse', ntrees=1000, verbose=100)\n",
    "\n",
    "model.fit(X, y, eval_sets=[{'X': X_test, 'y': y_test},])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will make prediction from different stages and will try to cluster paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 881 ms, sys: 314 ms, total: 1.2 s\n",
      "Wall time: 1.21 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45, 50000, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "iters_to_pred = np.arange(45).cumsum()\n",
    "\n",
    "test_staged_pred = model.predict_staged(X_test, iterations=iters_to_pred)\n",
    "# shape - (iterations, objects, output_dim)\n",
    "test_staged_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.76091595e+03, 7.91277798e+03, 6.88692004e+03, 6.62394329e+03,\n",
       "       5.07055708e+03, 2.98405447e+03, 1.90369454e+03, 1.42643350e+03,\n",
       "       1.02466591e+03, 5.42772313e+02, 2.73758818e+02, 1.03262352e+02,\n",
       "       7.15182801e+00, 5.33727182e+00, 2.04351677e+01, 1.29328979e+01,\n",
       "       9.64889161e+00, 1.40341080e+01, 9.99066560e+00, 1.22498699e+01,\n",
       "       1.40067976e+01, 1.84562880e+01, 1.60255573e+01, 1.60130986e+01,\n",
       "       1.84176320e+01, 1.70986568e+01, 1.78987097e+01, 1.90122375e+01,\n",
       "       2.24470121e+01, 2.29832696e+01, 2.36874766e+01, 2.51050573e+01,\n",
       "       2.08873772e+01, 1.90738303e+01, 1.98194901e+01, 1.88469976e+01,\n",
       "       1.73786778e+01, 2.01084945e+01, 2.08516176e+01, 2.05897623e+01,\n",
       "       2.08362914e+01, 2.09833055e+01, 1.89430398e+01, 1.98024432e+01,\n",
       "       2.25277642e+01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_paths = ((y_test[np.newaxis, :] - test_staged_pred[..., 0]) ** 2).T\n",
    "error_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cluster tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.cluster_tree.ClusterCandidates at 0x7f7fe478de20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from py_boost.gpu.cluster_tree import ClusterCandidates\n",
    "\n",
    "clustering = ClusterCandidates(depth_range=list(range(1, 7)), min_data_in_leaf=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clustering.fit(X_test, error_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_candidates = clustering.predict(X_test)\n",
    "# shape - (n_candidates, n_objects, 1)\n",
    "cluster_candidates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3, 4, 6, 9],\n",
       "       [0, 2, 3, 4, 6, 9],\n",
       "       [0, 2, 3, 4, 6, 9],\n",
       "       ...,\n",
       "       [0, 2, 2, 3, 5, 8],\n",
       "       [0, 2, 2, 3, 4, 6],\n",
       "       [0, 2, 3, 4, 6, 9]], dtype=uint32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  5,  7, 10], dtype=uint32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_candidates.max(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda_py38",
   "language": "python",
   "name": "anaconda_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
