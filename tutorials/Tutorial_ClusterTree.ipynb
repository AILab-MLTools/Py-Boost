{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of cluster tree usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation (if needed)\n",
    "\n",
    "**Note**: replace cupy-cuda110 with your cuda version!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cupy-cuda110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall py-boost\n",
    "# !cd ..; bash build_package.sh\n",
    "# !pip install ../dist/Py_Boost-0.1.8-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Optional: set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# simple case - just one class is used\n",
    "from py_boost import GradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of dummy regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.07 s, sys: 1.34 s, total: 3.41 s\n",
      "Wall time: 782 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = make_regression(150000, 100, n_targets=1, random_state=42)\n",
    "X_test, y_test = X[:50000], y[:50000]\n",
    "X, y = X[-50000:], y[-50000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a GBDT model\n",
    "\n",
    "The only argument required here is a loss function. It, together with the input target shape, determines the task type. The loss function can be passed as a Loss instance or using a string alias:\n",
    "\n",
    "* ***'mse'*** for the regression/multitask regression\n",
    "* ***'msle'*** for the regression/multitask regression\n",
    "* ***'bce'*** for the binary/multilabel classification\n",
    "* ***'crossentropy'*** for the multiclassification\n",
    "\n",
    "Training is simply done by calling the .fit metod. Possible argumentsare the following:\n",
    "\n",
    "* ***'X'*** \n",
    "* ***'y'*** \n",
    "* ***'sample_weight'*** \n",
    "* ***'eval_sets'***  \n",
    "A validation set is passed as a list of dicts with possible keys ['X', 'y', 'sample_weight']. Note: if multiple valid sets are passed, the best model is selected using the last one.\n",
    "\n",
    "#### The example below illustrates how to train a simple regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:52:21] Stdout logging level is INFO.\n",
      "[19:52:21] GDBT train starts. Max iter 1000, early stopping rounds 100\n",
      "[19:52:21] Iter 0; Sample 0, rmse = 175.0854022376131; \n",
      "[19:52:22] Iter 100; Sample 0, rmse = 34.70492128150738; \n",
      "[19:52:23] Iter 200; Sample 0, rmse = 18.875099554835995; \n",
      "[19:52:23] Iter 300; Sample 0, rmse = 15.978998689640951; \n",
      "[19:52:24] Iter 400; Sample 0, rmse = 15.373219194770174; \n",
      "[19:52:25] Iter 500; Sample 0, rmse = 15.218443982066903; \n",
      "[19:52:26] Iter 600; Sample 0, rmse = 15.164208733705237; \n",
      "[19:52:27] Iter 700; Sample 0, rmse = 15.094296333644555; \n",
      "[19:52:28] Iter 800; Sample 0, rmse = 15.02916963023134; \n",
      "[19:52:29] Iter 900; Sample 0, rmse = 14.965925240030174; \n",
      "[19:52:29] Iter 999; Sample 0, rmse = 14.916092422911172; \n",
      "CPU times: user 11.8 s, sys: 908 ms, total: 12.7 s\n",
      "Wall time: 11.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f24280be130>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse', ntrees=1000, verbose=100)\n",
    "\n",
    "model.fit(X, y, eval_sets=[{'X': X_test, 'y': y_test},])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will make prediction from different stages and will try to cluster paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 902 ms, sys: 358 ms, total: 1.26 s\n",
      "Wall time: 1.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45, 50000, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "iters_to_pred = np.arange(45).cumsum()\n",
    "\n",
    "test_staged_pred = model.predict_staged(X_test, iterations=iters_to_pred)\n",
    "# shape - (iterations, objects, output_dim)\n",
    "test_staged_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.76091614e+03, 7.91277821e+03, 6.88692060e+03, 6.62394368e+03,\n",
       "       5.07055708e+03, 2.98405530e+03, 1.90369454e+03, 1.42643322e+03,\n",
       "       1.02466615e+03, 5.42771424e+02, 2.73757809e+02, 1.03261732e+02,\n",
       "       7.15174639e+00, 5.33720132e+00, 2.04350297e+01, 1.29327882e+01,\n",
       "       9.64879681e+00, 1.40339937e+01, 9.99056914e+00, 1.22497631e+01,\n",
       "       1.40067405e+01, 1.84562225e+01, 1.60254962e+01, 1.60130375e+01,\n",
       "       1.84175665e+01, 1.70985937e+01, 1.78986452e+01, 1.90121710e+01,\n",
       "       2.24468675e+01, 2.29831233e+01, 2.36873280e+01, 2.51048279e+01,\n",
       "       2.08870983e+01, 1.90735637e+01, 1.98192184e+01, 1.88467989e+01,\n",
       "       1.73784870e+01, 2.01083576e+01, 2.08514782e+01, 2.05896238e+01,\n",
       "       2.08361521e+01, 2.09831657e+01, 1.89429070e+01, 1.98022395e+01,\n",
       "       2.25275469e+01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_paths = ((y_test[np.newaxis, :] - test_staged_pred[..., 0]) ** 2).T\n",
    "error_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cluster tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_boost.gpu.cluster_tree import ClusterCandidates\n",
    "\n",
    "clustering = ClusterCandidates(depth_range=list(range(1, 7)), min_data_in_leaf=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.59 s, sys: 36 ms, total: 1.63 s\n",
      "Wall time: 281 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.cluster_tree.ClusterCandidates at 0x7f21881e9a90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clustering.fit(X_test, error_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_candidates = clustering.predict(X_test)\n",
    "# shape - (n_candidates, n_objects, 1)\n",
    "cluster_candidates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3, 4, 6, 9],\n",
       "       [0, 2, 3, 4, 6, 9],\n",
       "       [0, 2, 3, 4, 6, 9],\n",
       "       ...,\n",
       "       [0, 2, 2, 3, 5, 8],\n",
       "       [0, 2, 2, 3, 4, 6],\n",
       "       [0, 2, 3, 4, 6, 9]], dtype=uint32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  5,  7, 10], dtype=uint32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_candidates.max(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda_py38",
   "language": "python",
   "name": "anaconda_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
