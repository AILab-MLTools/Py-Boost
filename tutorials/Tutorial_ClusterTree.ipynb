{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The simpliest usage example of py_boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation (if needed)\n",
    "\n",
    "**Note**: replace cupy-cuda110 with your cuda version!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install cupy-cuda110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall py-boost\n",
    "# !cd ..; bash build_package.sh\n",
    "# !pip install ../dist/Py_Boost-0.1.8-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Optional: set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# simple case - just one class is used\n",
    "from py_boost import GradientBoosting, CrossValidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of dummy regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.05 s, sys: 1.36 s, total: 3.41 s\n",
      "Wall time: 792 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = make_regression(150000, 100, n_targets=1, random_state=42)\n",
    "X_test, y_test = X[:50000], y[:50000]\n",
    "X, y = X[-50000:], y[-50000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a GBDT model\n",
    "\n",
    "The only argument required here is a loss function. It, together with the input target shape, determines the task type. The loss function can be passed as a Loss instance or using a string alias:\n",
    "\n",
    "* ***'mse'*** for the regression/multitask regression\n",
    "* ***'msle'*** for the regression/multitask regression\n",
    "* ***'bce'*** for the binary/multilabel classification\n",
    "* ***'crossentropy'*** for the multiclassification\n",
    "\n",
    "Training is simply done by calling the .fit metod. Possible argumentsare the following:\n",
    "\n",
    "* ***'X'*** \n",
    "* ***'y'*** \n",
    "* ***'sample_weight'*** \n",
    "* ***'eval_sets'***  \n",
    "A validation set is passed as a list of dicts with possible keys ['X', 'y', 'sample_weight']. Note: if multiple valid sets are passed, the best model is selected using the last one.\n",
    "\n",
    "#### The example below illustrates how to train a simple regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:46:58] Stdout logging level is INFO.\n",
      "[19:46:58] GDBT train starts. Max iter 1000, early stopping rounds 100\n",
      "[19:46:58] Iter 0; Sample 0, rmse = 175.08540219165158; \n",
      "[19:46:59] Iter 100; Sample 0, rmse = 34.70489960538339; \n",
      "[19:47:00] Iter 200; Sample 0, rmse = 18.875264744140104; \n",
      "[19:47:00] Iter 300; Sample 0, rmse = 15.979051235180613; \n",
      "[19:47:01] Iter 400; Sample 0, rmse = 15.373399030728404; \n",
      "[19:47:02] Iter 500; Sample 0, rmse = 15.218665059712949; \n",
      "[19:47:03] Iter 600; Sample 0, rmse = 15.164454086341598; \n",
      "[19:47:04] Iter 700; Sample 0, rmse = 15.094543783594625; \n",
      "[19:47:05] Iter 800; Sample 0, rmse = 15.029503808203762; \n",
      "[19:47:06] Iter 900; Sample 0, rmse = 14.966281468540894; \n",
      "[19:47:06] Iter 999; Sample 0, rmse = 14.916428475784219; \n",
      "CPU times: user 11.8 s, sys: 808 ms, total: 12.6 s\n",
      "Wall time: 11.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f134527e4f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse', ntrees=1000, verbose=100)\n",
    "\n",
    "model.fit(X, y, eval_sets=[{'X': X_test, 'y': y_test},])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will make prediction from different stages and will try to cluster paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 901 ms, sys: 330 ms, total: 1.23 s\n",
      "Wall time: 1.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45, 50000, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "iters_to_pred = np.arange(45).cumsum()\n",
    "\n",
    "test_staged_pred = model.predict_staged(X_test, iterations=iters_to_pred)\n",
    "# shape - (iterations, objects, output_dim)\n",
    "test_staged_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.76091618e+03, 7.91277819e+03, 6.88692028e+03, 6.62394368e+03,\n",
       "       5.07055804e+03, 2.98405530e+03, 1.90369521e+03, 1.42643322e+03,\n",
       "       1.02466640e+03, 5.42772313e+02, 2.73758818e+02, 1.03262352e+02,\n",
       "       7.15190962e+00, 5.33730708e+00, 2.04352367e+01, 1.29329528e+01,\n",
       "       9.64893900e+00, 1.40341652e+01, 9.99071383e+00, 1.22499233e+01,\n",
       "       1.40068547e+01, 1.84563536e+01, 1.60256184e+01, 1.60131597e+01,\n",
       "       1.84176975e+01, 1.70987199e+01, 1.78987743e+01, 1.90123040e+01,\n",
       "       2.24470844e+01, 2.29833427e+01, 2.36875508e+01, 2.51050573e+01,\n",
       "       2.08873075e+01, 1.90737636e+01, 1.98194222e+01, 1.88469314e+01,\n",
       "       1.73786142e+01, 2.01084945e+01, 2.08516872e+01, 2.05898315e+01,\n",
       "       2.08363611e+01, 2.09833754e+01, 1.89431062e+01, 1.98025111e+01,\n",
       "       2.25278366e+01])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_paths = ((y_test[np.newaxis, :] - test_staged_pred[..., 0]) ** 2).T\n",
    "error_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cluster tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.cluster_tree.ClusterCandidates at 0x7f109acb7820>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from py_boost.gpu.cluster_tree import ClusterCandidates\n",
    "\n",
    "clustering = ClusterCandidates(depth_range=list(range(1, 7)), min_data_in_leaf=100)\n",
    "clustering.fit(X_test, error_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 50000, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_candidates = clustering.predict_leaves(X_test)\n",
    "# shape - (n_candidates, n_objects, 1)\n",
    "cluster_candidates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3, 4, 6, 9],\n",
       "       [0, 2, 3, 4, 6, 9],\n",
       "       [0, 2, 3, 4, 6, 9],\n",
       "       ...,\n",
       "       [0, 2, 2, 3, 5, 8],\n",
       "       [0, 2, 2, 3, 4, 6],\n",
       "       [0, 2, 3, 4, 6, 9]], dtype=uint32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_candidates[..., 0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  5,  7, 10], dtype=uint32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_candidates[..., 0].T.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda_py38",
   "language": "python",
   "name": "anaconda_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
